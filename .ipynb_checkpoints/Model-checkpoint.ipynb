{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Titanic Dataset Model\n",
    "====================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Data\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(Path.cwd() / 'Data')\n",
    "\n",
    "df_train = pd.read_csv(data_path / 'train.csv')\n",
    "df_test = pd.read_csv(data_path / 'test.csv')\n",
    "df_gender_sub = pd.read_csv(data_path / 'gender_submission.csv')\n",
    "\n",
    "list_of_df = [df_train, df_test]\n",
    "list_of_df_names = [\"Train\", \"Test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the Data Into Train and Test Datasets\n",
    "-------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmptyValuesRowRemover:\n",
    "    \n",
    "    def __init__(self, columns=[]):\n",
    "        self.columns = columns\n",
    "        assert type(columns)==list, \"This class expects a list of columns to be passed at initiation.\"\n",
    "    \n",
    "    def Remover(self, X):\n",
    "        if self.columns == []:\n",
    "            self.column_list = list(X)\n",
    "        else:\n",
    "            self.column_list = self.columns\n",
    "        self.list_of_bools = []\n",
    "        for column in self.column_list:\n",
    "            X = X.loc[X.loc[:,column].notnull()]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HonorificExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "        \n",
    "    # dictionary to map to generate the new feature vector\n",
    "    title_dictionary = {\n",
    "        \"capt\":\"Officer\", \n",
    "        \"col\":\"Officer\", \n",
    "        \"major\":\"Officer\", \n",
    "        \"dr\":\"Officer\",\n",
    "        \"jonkheer\":\"Royalty\",\n",
    "        \"rev\":\"Officer\",\n",
    "        \"countess\":\"Royalty\",\n",
    "        \"dona\":\"Royalty\",\n",
    "        \"don\":\"Royalty\",\n",
    "        \"mr\":\"Mr\",\n",
    "        \"mme\":\"Mrs\",\n",
    "        \"ms\":\"Mrs\",\n",
    "        \"mrs\":\"Mrs\",\n",
    "        \"miss\":\"Miss\",\n",
    "        \"mlle\":\"Miss\",\n",
    "        \"master\":\"Master\",\n",
    "        \"nan\":\"Mr\"\n",
    "    }\n",
    "    \n",
    "    def get_title(self, string):\n",
    "        regex = re.compile(\n",
    "            r'Mr|Don|Major|Capt|Jonkheer|Rev|Col|Dr|Mrs|Countess|Dona|Mme|Ms|Miss|Mlle|Master', \n",
    "            re.IGNORECASE\n",
    "        )\n",
    "        results = regex.search(string)\n",
    "        if results != None:\n",
    "            return(results.group().lower())\n",
    "        else:\n",
    "            return(str(np.nan))\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X['Title'] = X.loc[:,self.column].apply(self.get_title)\n",
    "        X['Title'] = X.loc[:,'Title'].map(self.title_dictionary)\n",
    "        X = X.drop(self.column, axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrePreprocessingPipe = Pipeline(\n",
    "    steps=[\n",
    "#         (\"evrr\", EmptyValuesRowRemover(columns=[\"Age\"])),\n",
    "        (\"he\", HonorificExtractor(column=\"Name\"))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['Age', 'Fare', 'SibSp']\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "PreprocessingPipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"pp\", PrePreprocessingPipe), \n",
    "        (\"ct\", ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', numeric_transformer, numeric_features),\n",
    "                ('cat', categorical_transformer, categorical_features)\n",
    "            ]\n",
    "        ))\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = Pipeline(\n",
    "    steps=[\n",
    "        ('pp', PreprocessingPipeline),\n",
    "        ('classifier', LogisticRegression(solver='lbfgs'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "df_train = EmptyValuesRowRemover(columns=[\"Age\"]).Remover(df_train)\n",
    "df_test = EmptyValuesRowRemover(columns=[\"Age\"]).Remover(df_train)\n",
    "\n",
    "X_train = df_train.drop('Survived', axis='columns')\n",
    "X_test = df_test\n",
    "y_train = df_train.loc[:,'Survived']\n",
    "\n",
    "Model.fit(X_train, y_train.values.ravel())\n",
    "y_predict = Model.predict(X_test)\n",
    "df_results = pd.DataFrame({\"PassengerId\": X_test.PassengerId, \"Survived\": y_predict})\n",
    "df_results.to_csv(\"submission_NEW.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714, 12)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
